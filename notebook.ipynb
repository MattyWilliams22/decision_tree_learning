{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-64. -56. -61. ... -82. -81.   1.]\n",
      " [-68. -57. -61. ... -85. -85.   1.]\n",
      " [-63. -60. -60. ... -85. -84.   1.]\n",
      " ...\n",
      " [-62. -59. -46. ... -87. -88.   4.]\n",
      " [-62. -58. -52. ... -90. -85.   4.]\n",
      " [-59. -50. -45. ... -88. -87.   4.]]\n",
      "[[-59. -53. -51. ... -79. -87.   4.]\n",
      " [-66. -53. -59. ... -81. -79.   1.]\n",
      " [-41. -57. -63. ... -66. -65.   2.]\n",
      " ...\n",
      " [-57. -54. -56. ... -79. -82.   1.]\n",
      " [-56. -52. -50. ... -85. -88.   3.]\n",
      " [-46. -54. -47. ... -80. -73.   3.]]\n"
     ]
    }
   ],
   "source": [
    "# decision_tree_learning\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Load datasets from files\n",
    "clean_dataset = np.loadtxt(\"wifi_db/clean_dataset.txt\", delimiter=\"\\t\")\n",
    "noisy_dataset = np.loadtxt(\"wifi_db/noisy_dataset.txt\", delimiter=\" \")\n",
    "print(clean_dataset)\n",
    "print(noisy_dataset)\n",
    "\n",
    "SIGNAL_COUNT = 7\n",
    "CLASS_COUNT = 4\n",
    "\n",
    "def all_same_label(dataset) -> bool:\n",
    "  # check if all samples have the same label\n",
    "  for i in range(len(dataset)):\n",
    "    if dataset[i][SIGNAL_COUNT] != dataset[0][SIGNAL_COUNT]:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "def entropy(dataset) -> float:\n",
    "  # H(D)\n",
    "  \n",
    "  # To implement\n",
    "\n",
    "  return 0.0\n",
    "\n",
    "def calculate_IG(l_dataset, r_dataset) -> float:\n",
    "  # IG(D1, D2) = H(D) - H(D1, D2)\n",
    "  # H(D1, D2) = (|D1|/|D|)H(D1) + (|D2|/|D|)H(D2)\n",
    "\n",
    "  # To implement\n",
    "\n",
    "  return 0.0\n",
    "\n",
    "def pick_split_value(dataset, attribute) -> Tuple[float, float]:\n",
    "  # find the best value to split by\n",
    "  highest_IG = 0.0\n",
    "  best_value = 0.0\n",
    "\n",
    "  np.argsort(dataset[:,attribute])\n",
    "\n",
    "  for i in range(len(dataset)):\n",
    "    l_dataset = dataset[:i]\n",
    "    r_dataset = dataset[i:]\n",
    "\n",
    "    information_gain = calculate_IG(l_dataset, r_dataset)\n",
    "\n",
    "    if information_gain > highest_IG:\n",
    "      highest_IG = information_gain\n",
    "      best_value = dataset[i][attribute]\n",
    "  \n",
    "  return (highest_IG, best_value)\n",
    "\n",
    "def find_split(dataset):\n",
    "  # find the best split\n",
    "  best_attribute = 0\n",
    "  best_value = 0.0\n",
    "  best_IG = 0.0\n",
    "\n",
    "  for i in range(SIGNAL_COUNT):\n",
    "    (information_gain, value) = pick_split_value(dataset, i)\n",
    "\n",
    "    if information_gain > best_IG:\n",
    "      best_IG = information_gain\n",
    "      best_attribute = i\n",
    "      best_value = value\n",
    "  \n",
    "  return (best_attribute, best_value)\n",
    "\n",
    "def decision_tree_learning(dataset, depth) -> Tuple[dict, int]:\n",
    "  if all_same_label(dataset):\n",
    "    return ({\"value\": dataset[0][SIGNAL_COUNT]}, depth)\n",
    "  else:\n",
    "    (split_attribute, split_value) = find_split(dataset)\n",
    "\n",
    "    l_dataset = dataset[dataset[:,split_attribute] < split_value]\n",
    "    r_dataset = dataset[dataset[:,split_attribute] >= split_value]\n",
    "\n",
    "    node = {\"split_attribute\": split_attribute, \"split_value\": split_value}\n",
    "\n",
    "    l_branch, l_depth = decision_tree_learning(l_dataset, depth+1)\n",
    "    r_branch, r_depth = decision_tree_learning(r_dataset, depth+1)\n",
    "\n",
    "    node[\"l_branch\"] = l_branch\n",
    "    node[\"r_branch\"] = r_branch\n",
    "\n",
    "    return (node, max(l_depth, r_depth))\n",
    "\n",
    "# print(decision_tree_learning(clean_dataset, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree visualiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification metrics generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
